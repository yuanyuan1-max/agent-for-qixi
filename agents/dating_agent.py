"""
çº¦ä¼šæŒ‡å—æ™ºèƒ½ä½“æ¨¡å—
"""
from typing import List, Dict, Any, Optional
from langchain.schema import Document
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

from core.llm_manager import LLMManager
from core.vector_store import VectorStore
from tools.web_search import WebSearchTool
from utils.logger import get_logger

logger = get_logger(__name__)

class DatingAgent:
    """çº¦ä¼šæŒ‡å—æ™ºèƒ½ä½“"""
    
    def __init__(self):
        self.llm_manager = LLMManager()
        self.vector_store = VectorStore()
        self.web_search = WebSearchTool()
        self.qa_chain = None
        self._initialize()
    
    def _initialize(self):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“"""
        try:
            # åˆ›å»ºé—®ç­”é“¾
            self._create_qa_chain()
            
            # åˆå§‹åŒ–çŸ¥è¯†åº“
            self._initialize_knowledge_base()
            
            logger.info("çº¦ä¼šæŒ‡å—æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä½“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _create_qa_chain(self):
        """åˆ›å»ºé—®ç­”é“¾"""
        try:
            # åˆ›å»ºæç¤ºæ¨¡æ¿
            prompt_template = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸ƒå¤•çº¦ä¼šè§„åˆ’å¸ˆã€‚åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸ºç”¨æˆ·æä¾›è¯¦ç»†ã€å®ç”¨çš„çº¦ä¼šå»ºè®®ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·æä¾›:
1. çº¦ä¼šä¸»é¢˜å’Œæ°›å›´å»ºè®®
2. å…·ä½“æ´»åŠ¨å®‰æ’
3. æ—¶é—´è§„åˆ’å»ºè®®
4. åœ°ç‚¹æ¨è
5. æ³¨æ„äº‹é¡¹å’Œè´´å¿ƒæç¤º

è¯·ç”¨æ¸©æš–ã€ä¸“ä¸šçš„è¯­æ°”å›ç­”ï¼Œç¡®ä¿å»ºè®®å®ç”¨ä¸”æµªæ¼«ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ï¼Œè¯·åŸºäºä½ çš„ä¸“ä¸šçŸ¥è¯†æä¾›å»ºè®®ã€‚

çº¦ä¼šè§„åˆ’å¸ˆ:"""

            prompt = PromptTemplate(
                template=prompt_template,
                input_variables=["context", "question"]
            )
            
            # åˆ›å»ºæ£€ç´¢é—®ç­”é“¾ - ä½¿ç”¨LLMç®¡ç†å™¨çš„LLMå®ä¾‹
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm_manager.get_llm_for_rag(),
                chain_type="stuff",
                retriever=self.vector_store.vector_db.as_retriever(
                    search_kwargs={"k": 5}
                ),
                chain_type_kwargs={"prompt": prompt},
                return_source_documents=True
            )
            
            logger.info("é—®ç­”é“¾åˆ›å»ºæˆåŠŸ")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºé—®ç­”é“¾å¤±è´¥: {e}")
            raise
    
    def _initialize_knowledge_base(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“"""
        try:
            # æ£€æŸ¥å‘é‡æ•°æ®åº“æ˜¯å¦å·²æœ‰å†…å®¹
            stats = self.vector_store.get_collection_stats()
            
            if stats.get("document_count", 0) == 0:
                logger.info("çŸ¥è¯†åº“ä¸ºç©ºï¼Œå¼€å§‹åˆå§‹åŒ–åŸºç¡€çº¦ä¼šçŸ¥è¯†...")
                
                # æ·»åŠ åŸºç¡€çº¦ä¼šçŸ¥è¯†
                self._add_basic_dating_knowledge()
                
                # æœç´¢å¹¶æ·»åŠ æœ€æ–°çš„çº¦ä¼šä¿¡æ¯
                self._search_and_add_dating_info()
                
                logger.info("çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ")
            else:
                logger.info(f"çŸ¥è¯†åº“å·²æœ‰{stats.get('document_count', 0)}ä¸ªæ–‡æ¡£")
                
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–çŸ¥è¯†åº“å¤±è´¥: {e}")
    
    def _add_basic_dating_knowledge(self):
        """æ·»åŠ åŸºç¡€çº¦ä¼šçŸ¥è¯†"""
        basic_knowledge = [
            {
                "content": """
                ä¸ƒå¤•èŠ‚æ˜¯ä¸­å›½ä¼ ç»Ÿçš„æƒ…äººèŠ‚ï¼Œèµ·æºäºç‰›éƒç»‡å¥³çš„ç¾ä¸½ä¼ è¯´ã€‚è¿™ä¸€å¤©ï¼Œæƒ…ä¾£ä»¬ä¼šé€šè¿‡å„ç§æ–¹å¼è¡¨è¾¾çˆ±æ„ï¼Œåˆ›é€ æµªæ¼«çš„å›å¿†ã€‚

                æµªæ¼«çº¦ä¼šçš„åŸºæœ¬è¦ç´ ï¼š
                1. ç²¾å¿ƒå‡†å¤‡ï¼šæå‰è§„åˆ’ï¼Œæ³¨æ„ç»†èŠ‚
                2. ä¸ªæ€§åŒ–ï¼šæ ¹æ®å¯¹æ–¹çš„å–œå¥½å®šåˆ¶
                3. æ°›å›´è¥é€ ï¼šç¯å…‰ã€éŸ³ä¹ã€è£…é¥°ç­‰
                4. æƒŠå–œå…ƒç´ ï¼šæ„æƒ³ä¸åˆ°çš„å°æƒŠå–œ
                5. æƒ…æ„Ÿè¡¨è¾¾ï¼šçœŸè¯šçš„è¨€è¯­å’Œè¡ŒåŠ¨
                """,
                "metadata": {"type": "basic_knowledge", "category": "dating_fundamentals"}
            },
            {
                "content": """
                ç»å…¸çº¦ä¼šæ´»åŠ¨æ¨èï¼š
                1. çƒ›å…‰æ™šé¤ï¼šé€‰æ‹©æµªæ¼«é¤å…ï¼Œè¥é€ æ¸©é¦¨æ°›å›´
                2. ç”µå½±çº¦ä¼šï¼šé€‰æ‹©çˆ±æƒ…ç‰‡æˆ–å¯¹æ–¹å–œæ¬¢çš„ç±»å‹
                3. æˆ·å¤–æ´»åŠ¨ï¼šå…¬å›­æ•£æ­¥ã€é‡é¤ã€çœ‹æ˜Ÿæ˜Ÿ
                4. æ‰‹å·¥DIYï¼šä¸€èµ·åˆ¶ä½œæ‰‹å·¥è‰ºå“æˆ–çƒ¹é¥ª
                5. æƒŠå–œç¤¼ç‰©ï¼šç²¾å¿ƒæŒ‘é€‰æœ‰æ„ä¹‰çš„ç¤¼ç‰©
                6. æ—…è¡Œçº¦ä¼šï¼šçŸ­é€”æ—…è¡Œï¼Œåˆ›é€ å…±åŒå›å¿†
                """,
                "metadata": {"type": "basic_knowledge", "category": "dating_activities"}
            },
            {
                "content": """
                çº¦ä¼šæ³¨æ„äº‹é¡¹ï¼š
                1. æ—¶é—´å®‰æ’ï¼šåˆç†å®‰æ’æ—¶é—´ï¼Œé¿å…è¿‡äºç´§å‡‘
                2. é¢„ç®—æ§åˆ¶ï¼šæ ¹æ®ç»æµèƒ½åŠ›åˆ¶å®šè®¡åˆ’
                3. å¤©æ°”è€ƒè™‘ï¼šå…³æ³¨å¤©æ°”é¢„æŠ¥ï¼Œå‡†å¤‡å¤‡é€‰æ–¹æ¡ˆ
                4. äº¤é€šä¾¿åˆ©ï¼šé€‰æ‹©äº¤é€šä¾¿åˆ©çš„åœ°ç‚¹
                5. å®‰å…¨ç¬¬ä¸€ï¼šæ³¨æ„äººèº«å’Œè´¢äº§å®‰å…¨
                6. å°Šé‡å¯¹æ–¹ï¼šè€ƒè™‘å¯¹æ–¹çš„æ„Ÿå—å’Œæ„æ„¿
                """,
                "metadata": {"type": "basic_knowledge", "category": "dating_tips"}
            }
        ]
        
        # è½¬æ¢ä¸ºDocumentå¯¹è±¡
        documents = []
        for item in basic_knowledge:
            doc = Document(
                page_content=item["content"],
                metadata=item["metadata"]
            )
            documents.append(doc)
        
        # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        self.vector_store.add_documents(documents)
        logger.info("åŸºç¡€çº¦ä¼šçŸ¥è¯†æ·»åŠ å®Œæˆ")
    
    def _search_and_add_dating_info(self):
        """æœç´¢å¹¶æ·»åŠ çº¦ä¼šä¿¡æ¯"""
        try:
            # æœç´¢çº¦ä¼šç›¸å…³ä¿¡æ¯
            search_queries = [
                "ä¸ƒå¤•çº¦ä¼šåˆ›æ„",
                "æµªæ¼«çº¦ä¼šåœ°ç‚¹",
                "æƒ…ä¾£çº¦ä¼šæ´»åŠ¨",
                "çº¦ä¼šç¤¼ç‰©æ¨è"
            ]
            
            for query in search_queries:
                logger.info(f"æœç´¢: {query}")
                results = self.web_search.search_dating_ideas(query)
                
                if results:
                    # è½¬æ¢ä¸ºDocumentå¯¹è±¡
                    documents = []
                    for result in results[:3]:  # æ¯ä¸ªæŸ¥è¯¢å–å‰3ä¸ªç»“æœ
                        content = f"æ ‡é¢˜: {result['title']}\n\nå†…å®¹: {result['snippet']}\n\næ¥æº: {result['url']}"
                        doc = Document(
                            page_content=content,
                            metadata={
                                "type": "web_search",
                                "category": "dating_ideas",
                                "source": result["source"],
                                "url": result["url"],
                                "relevance_score": result["relevance_score"]
                            }
                        )
                        documents.append(doc)
                    
                    # æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
                    if documents:
                        self.vector_store.add_documents(documents)
                        logger.info(f"æ·»åŠ {len(documents)}ä¸ªæœç´¢ç»“æœåˆ°çŸ¥è¯†åº“")
                
        except Exception as e:
            logger.error(f"æœç´¢å¹¶æ·»åŠ çº¦ä¼šä¿¡æ¯å¤±è´¥: {e}")
    
    def plan_dating(self, user_query: str) -> Dict[str, Any]:
        """è§„åˆ’çº¦ä¼š"""
        try:
            logger.info(f"æ”¶åˆ°ç”¨æˆ·æŸ¥è¯¢: {user_query}")
            
            # é¦–å…ˆä½¿ç”¨RAGç³»ç»Ÿæ£€ç´¢ç›¸å…³çŸ¥è¯†
            logger.info("ğŸ” ä½¿ç”¨RAGç³»ç»Ÿæ£€ç´¢ç›¸å…³çŸ¥è¯†...")
            relevant_docs = self.vector_store.similarity_search(user_query, k=5)
            
            if relevant_docs:
                logger.info(f"âœ… æ‰¾åˆ°{len(relevant_docs)}ä¸ªç›¸å…³æ–‡æ¡£")
                
                # æ„å»ºåŒ…å«æ£€ç´¢å†…å®¹çš„æç¤º
                context_info = "\n\n".join([doc.page_content for doc in relevant_docs])
                enhanced_prompt = f"""
åŸºäºä»¥ä¸‹æ£€ç´¢åˆ°çš„çº¦ä¼šçŸ¥è¯†ï¼Œä¸ºç”¨æˆ·æä¾›è¯¦ç»†çš„çº¦ä¼šè§„åˆ’ï¼š

æ£€ç´¢åˆ°çš„çŸ¥è¯†ï¼š
{context_info}

ç”¨æˆ·éœ€æ±‚ï¼š{user_query}

è¯·æä¾›ï¼š
1. çº¦ä¼šä¸»é¢˜å’Œæ°›å›´å»ºè®®
2. å…·ä½“æ´»åŠ¨å®‰æ’
3. æ—¶é—´è§„åˆ’å»ºè®®
4. åœ°ç‚¹æ¨è
5. æ³¨æ„äº‹é¡¹å’Œè´´å¿ƒæç¤º

è¯·ç”¨æ¸©æš–ã€ä¸“ä¸šçš„è¯­æ°”å›ç­”ï¼Œç¡®ä¿å»ºè®®å®ç”¨ä¸”æµªæ¼«ã€‚
"""
                
                # ä½¿ç”¨LLMç”Ÿæˆå›ç­”
                logger.info("ğŸ¤– åŸºäºæ£€ç´¢å†…å®¹ç”Ÿæˆå›ç­”...")
                answer = self.llm_manager.generate(enhanced_prompt)
                
                result = {
                    "answer": answer,
                    "source_documents": [],
                    "search_results": [],
                    "rag_used": True
                }
                
                # æ·»åŠ æºæ–‡æ¡£ä¿¡æ¯
                for doc in relevant_docs:
                    result["source_documents"].append({
                        "content": doc.page_content[:200] + "...",
                        "metadata": doc.metadata
                    })
                
                logger.info("âœ… RAGç³»ç»Ÿå›ç­”ç”Ÿæˆå®Œæˆ")
                
            else:
                logger.info("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼Œç›´æ¥ä½¿ç”¨LLMç”Ÿæˆ...")
                answer = self.llm_manager.generate(user_query)
                
                result = {
                    "answer": answer,
                    "source_documents": [],
                    "search_results": [],
                    "rag_used": False
                }
            
            # å¦‚æœRAGç»“æœä¸å¤Ÿè¯¦ç»†ï¼Œè¿›è¡Œç½‘ç»œæœç´¢è¡¥å……
            if len(result["answer"]) < 300:
                logger.info("ğŸ” RAGç»“æœä¸å¤Ÿè¯¦ç»†ï¼Œè¿›è¡Œç½‘ç»œæœç´¢è¡¥å……...")
                search_results = self.web_search.search_dating_ideas(user_query)
                result["search_results"] = search_results[:3]
                
                # åŸºäºæœç´¢ç»“æœç”Ÿæˆè¡¥å……å»ºè®®
                if search_results:
                    enhanced_answer = self._enhance_answer_with_search(
                        result["answer"], search_results
                    )
                    result["answer"] = enhanced_answer
            
            logger.info("ğŸ¯ çº¦ä¼šè§„åˆ’å®Œæˆ")
            return result
                
        except Exception as e:
            logger.error(f"è§„åˆ’çº¦ä¼šå¤±è´¥: {e}")
            return {
                "answer": f"æŠ±æ­‰ï¼Œè§„åˆ’çº¦ä¼šæ—¶å‡ºç°é”™è¯¯: {str(e)}",
                "source_documents": [],
                "search_results": [],
                "rag_used": False
            }
    
    def _enhance_answer_with_search(self, original_answer: str, search_results: List[Dict[str, Any]]) -> str:
        """åŸºäºæœç´¢ç»“æœå¢å¼ºå›ç­”"""
        try:
            # æ„å»ºå¢å¼ºæç¤º
            search_context = "\n\n".join([
                f"æœç´¢ç»“æœ {i+1}:\næ ‡é¢˜: {result['title']}\nå†…å®¹: {result['snippet']}"
                for i, result in enumerate(search_results)
            ])
            
            enhancement_prompt = f"""
åŸºäºä»¥ä¸‹æœç´¢ç»“æœï¼Œè¯·ä¸ºåŸæœ‰çš„çº¦ä¼šå»ºè®®æä¾›æ›´è¯¦ç»†ã€æ›´å®ç”¨çš„è¡¥å……ä¿¡æ¯ï¼š

åŸæœ‰å»ºè®®ï¼š
{original_answer}

æœç´¢ç»“æœï¼š
{search_context}

è¯·æä¾›ï¼š
1. å…·ä½“çš„å®æ–½å»ºè®®
2. æ›´å¤šåˆ›æ„é€‰æ‹©
3. å®ç”¨çš„æ³¨æ„äº‹é¡¹
4. ä¸ªæ€§åŒ–å®šåˆ¶å»ºè®®

è¯·ä¿æŒæ¸©æš–ã€ä¸“ä¸šçš„è¯­æ°”ï¼Œç¡®ä¿å»ºè®®å®ç”¨ä¸”æµªæ¼«ã€‚
"""
            
            # ä½¿ç”¨LLMç”Ÿæˆå¢å¼ºå›ç­”
            enhanced_answer = self.llm_manager.generate(enhancement_prompt)
            
            # åˆå¹¶åŸæœ‰å›ç­”å’Œå¢å¼ºå†…å®¹
            final_answer = f"{original_answer}\n\nğŸ’¡ è¡¥å……å»ºè®®ï¼š\n{enhanced_answer}"
            
            return final_answer
            
        except Exception as e:
            logger.error(f"å¢å¼ºå›ç­”å¤±è´¥: {e}")
            return original_answer
    
    def get_agent_status(self) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½ä½“çŠ¶æ€"""
        try:
            return {
                "llm_ready": self.llm_manager.is_ready(),
                "vector_db_stats": self.vector_store.get_collection_stats(),
                "model_info": self.llm_manager.get_model_info(),
                "rag_chain_ready": self.qa_chain is not None
            }
        except Exception as e:
            logger.error(f"è·å–æ™ºèƒ½ä½“çŠ¶æ€å¤±è´¥: {e}")
            return {"error": str(e)}
